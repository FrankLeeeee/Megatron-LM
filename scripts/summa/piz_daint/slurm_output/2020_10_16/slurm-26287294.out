nid04896:17738:17738 [0] NCCL INFO Bootstrap : Using [0]ipogif0:148.187.51.71<0>
nid04896:17738:17738 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).
libibverbs: Could not locate libibgni (/usr/lib64/libibgni.so.1: undefined symbol: verbs_uninit_context)
libibverbs: Warning: couldn't open config directory '/opt/cray/rdma-core/22.3-7.0.2.1_2.21__g42f5f32b.ari/etc/libibverbs.d'.
nid04896:17738:17738 [0] NCCL INFO NET/IB : No device found.
nid04896:17738:17738 [0] NCCL INFO NET/Socket : Using [0]ipogif0:148.187.51.71<0>
NCCL version 2.4.8+cuda10.1
nid04896:17738:17762 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
nid07238:11625:11625 [0] NCCL INFO Bootstrap : Using [0]ipogif0:148.187.60.127<0>
nid05847:21543:21543 [0] NCCL INFO Bootstrap : Using [0]ipogif0:148.187.55.6<0>
nid06116:1031:1031 [0] NCCL INFO Bootstrap : Using [0]ipogif0:148.187.56.21<0>
nid05847:21543:21543 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).
nid07238:11625:11625 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).
libibverbs: Could not locate libibgni (/usr/lib64/libibgni.so.1: undefined symbol: verbs_uninit_context)
libibverbs: Warning: couldn't open config directory '/opt/cray/rdma-core/22.3-7.0.2.1_2.21__g42f5f32b.ari/etc/libibverbs.d'.
nid05847:21543:21543 [0] NCCL INFO NET/IB : No device found.
nid05847:21543:21543 [0] NCCL INFO NET/Socket : Using [0]ipogif0:148.187.55.6<0>
libibverbs: Could not locate libibgni (/usr/lib64/libibgni.so.1: undefined symbol: verbs_uninit_context)
libibverbs: Warning: couldn't open config directory '/opt/cray/rdma-core/22.3-7.0.2.1_2.21__g42f5f32b.ari/etc/libibverbs.d'.
nid07238:11625:11625 [0] NCCL INFO NET/IB : No device found.
nid07238:11625:11625 [0] NCCL INFO NET/Socket : Using [0]ipogif0:148.187.60.127<0>
nid06116:1031:1031 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).
libibverbs: Could not locate libibgni (/usr/lib64/libibgni.so.1: undefined symbol: verbs_uninit_context)
libibverbs: Warning: couldn't open config directory '/opt/cray/rdma-core/22.3-7.0.2.1_2.21__g42f5f32b.ari/etc/libibverbs.d'.
nid06116:1031:1031 [0] NCCL INFO NET/IB : No device found.
nid06116:1031:1031 [0] NCCL INFO NET/Socket : Using [0]ipogif0:148.187.56.21<0>
nid05847:21543:21557 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
nid06116:1031:1045 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
nid07238:11625:11640 [0] NCCL INFO Setting affinity for GPU 0 to ffffff
nid07238:11625:11640 [0] NCCL INFO Could not find real path of /sys/class/net/ipogif0/device
nid07238:11625:11640 [0] NCCL INFO include/net.h:19 -> 2
nid07238:11625:11640 [0] NCCL INFO CUDA Dev 0[0], Socket NIC distance :  SYS
nid06116:1031:1045 [0] NCCL INFO Could not find real path of /sys/class/net/ipogif0/device
nid06116:1031:1045 [0] NCCL INFO include/net.h:19 -> 2
nid06116:1031:1045 [0] NCCL INFO CUDA Dev 0[0], Socket NIC distance :  SYS
nid05847:21543:21557 [0] NCCL INFO Could not find real path of /sys/class/net/ipogif0/device
nid05847:21543:21557 [0] NCCL INFO include/net.h:19 -> 2
nid04896:17738:17762 [0] NCCL INFO Could not find real path of /sys/class/net/ipogif0/device
nid04896:17738:17762 [0] NCCL INFO include/net.h:19 -> 2
nid04896:17738:17762 [0] NCCL INFO CUDA Dev 0[0], Socket NIC distance :  SYS
nid05847:21543:21557 [0] NCCL INFO CUDA Dev 0[0], Socket NIC distance :  SYS
nid04896:17738:17762 [0] NCCL INFO Channel 00 :    0   1   2   3
nid07238:11625:11640 [0] NCCL INFO Could not find real path of /sys/class/net/ipogif0/device
nid07238:11625:11640 [0] NCCL INFO include/net.h:19 -> 2
nid05847:21543:21557 [0] NCCL INFO Could not find real path of /sys/class/net/ipogif0/device
nid04896:17738:17762 [0] NCCL INFO Could not find real path of /sys/class/net/ipogif0/device
nid04896:17738:17762 [0] NCCL INFO include/net.h:19 -> 2
nid06116:1031:1045 [0] NCCL INFO Could not find real path of /sys/class/net/ipogif0/device
nid06116:1031:1045 [0] NCCL INFO include/net.h:19 -> 2
nid05847:21543:21557 [0] NCCL INFO include/net.h:19 -> 2
nid05847:21543:21557 [0] NCCL INFO Ring 00 : 0 -> 1 [receive] via NET/Socket/0
nid04896:17738:17762 [0] NCCL INFO Ring 00 : 3 -> 0 [receive] via NET/Socket/0
nid06116:1031:1045 [0] NCCL INFO Ring 00 : 1 -> 2 [receive] via NET/Socket/0
nid07238:11625:11640 [0] NCCL INFO Ring 00 : 2 -> 3 [receive] via NET/Socket/0
nid05847:21543:21557 [0] NCCL INFO NET/Socket: Using 1 threads and 1 sockets per thread
nid04896:17738:17762 [0] NCCL INFO NET/Socket: Using 1 threads and 1 sockets per thread
nid06116:1031:1045 [0] NCCL INFO NET/Socket: Using 1 threads and 1 sockets per thread
nid07238:11625:11640 [0] NCCL INFO NET/Socket: Using 1 threads and 1 sockets per thread
nid05847:21543:21557 [0] NCCL INFO Ring 00 : 1 -> 2 [send] via NET/Socket/0
nid07238:11625:11640 [0] NCCL INFO Ring 00 : 3 -> 0 [send] via NET/Socket/0
nid04896:17738:17762 [0] NCCL INFO Ring 00 : 0 -> 1 [send] via NET/Socket/0
nid06116:1031:1045 [0] NCCL INFO Ring 00 : 2 -> 3 [send] via NET/Socket/0
nid04896:17738:17762 [0] NCCL INFO Using 256 threads, Min Comp Cap 6, Trees disabled
nid07238:11625:11640 [0] NCCL INFO comm 0x2aab38002260 rank 3 nranks 4 cudaDev 0 nvmlDev 0 - Init COMPLETE
nid05847:21543:21557 [0] NCCL INFO comm 0x2aab38002260 rank 1 nranks 4 cudaDev 0 nvmlDev 0 - Init COMPLETE
nid04896:17738:17762 [0] NCCL INFO comm 0x2aab40002260 rank 0 nranks 4 cudaDev 0 nvmlDev 0 - Init COMPLETE
nid04896:17738:17738 [0] NCCL INFO Launch mode Parallel
nid06116:1031:1045 [0] NCCL INFO comm 0x2aab38002260 rank 2 nranks 4 cudaDev 0 nvmlDev 0 - Init COMPLETE
Traceback (most recent call last):
  File "main.py", line 50, in <module>
    main()
  File "main.py", line 46, in main
    run(**args_dict)
  File "/users/youyang9/lsg/Megatron-LM/scripts/summa/piz_daint/megatron_mlp.py", line 260, in megatron_mlp_run
    mlp = ParallelMLP(hidden_size=hidden_dim, world_size=world_size).cuda()
  File "/users/youyang9/lsg/Megatron-LM/scripts/summa/piz_daint/megatron_mlp.py", line 203, in __init__
    self.dense_h_to_4h = ColumnParallelLinear(
  File "/users/youyang9/lsg/Megatron-LM/scripts/summa/piz_daint/megatron_mlp.py", line 75, in __init__
    self.weight = Parameter(torch.Tensor(self.output_size_per_partition,
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 262144000000 bytes. Error code 12 (Cannot allocate memory)
Traceback (most recent call last):
  File "main.py", line 50, in <module>
    main()
  File "main.py", line 46, in main
    run(**args_dict)
  File "/users/youyang9/lsg/Megatron-LM/scripts/summa/piz_daint/megatron_mlp.py", line 260, in megatron_mlp_run
    mlp = ParallelMLP(hidden_size=hidden_dim, world_size=world_size).cuda()
  File "/users/youyang9/lsg/Megatron-LM/scripts/summa/piz_daint/megatron_mlp.py", line 203, in __init__
    self.dense_h_to_4h = ColumnParallelLinear(
  File "/users/youyang9/lsg/Megatron-LM/scripts/summa/piz_daint/megatron_mlp.py", line 75, in __init__
    self.weight = Parameter(torch.Tensor(self.output_size_per_partition,
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 262144000000 bytes. Error code 12 (Cannot allocate memory)
Traceback (most recent call last):
  File "main.py", line 50, in <module>
    main()
  File "main.py", line 46, in main
    run(**args_dict)
  File "/users/youyang9/lsg/Megatron-LM/scripts/summa/piz_daint/megatron_mlp.py", line 260, in megatron_mlp_run
    mlp = ParallelMLP(hidden_size=hidden_dim, world_size=world_size).cuda()
  File "/users/youyang9/lsg/Megatron-LM/scripts/summa/piz_daint/megatron_mlp.py", line 203, in __init__
    self.dense_h_to_4h = ColumnParallelLinear(
  File "/users/youyang9/lsg/Megatron-LM/scripts/summa/piz_daint/megatron_mlp.py", line 75, in __init__
    self.weight = Parameter(torch.Tensor(self.output_size_per_partition,
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 262144000000 bytes. Error code 12 (Cannot allocate memory)
Traceback (most recent call last):
  File "main.py", line 50, in <module>
    main()
  File "main.py", line 46, in main
    run(**args_dict)
  File "/users/youyang9/lsg/Megatron-LM/scripts/summa/piz_daint/megatron_mlp.py", line 260, in megatron_mlp_run
    mlp = ParallelMLP(hidden_size=hidden_dim, world_size=world_size).cuda()
  File "/users/youyang9/lsg/Megatron-LM/scripts/summa/piz_daint/megatron_mlp.py", line 203, in __init__
    self.dense_h_to_4h = ColumnParallelLinear(
  File "/users/youyang9/lsg/Megatron-LM/scripts/summa/piz_daint/megatron_mlp.py", line 75, in __init__
    self.weight = Parameter(torch.Tensor(self.output_size_per_partition,
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 262144000000 bytes. Error code 12 (Cannot allocate memory)
srun: error: nid06116: task 2: Exited with exit code 1
srun: Terminating job step 26287294.0
srun: error: nid07238: task 3: Exited with exit code 1
srun: error: nid05847: task 1: Exited with exit code 1
srun: error: nid04896: task 0: Exited with exit code 1
